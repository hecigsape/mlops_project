import tensorflow as tf
import pandas as pd
import os
from transformers import TFBertForSequenceClassification, BertTokenizer
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# ðŸ“Œ ConfiguraciÃ³n
MODEL_PATH = "src/models/checkpoints/bert_finetuned"
DATA_PATH = "data/processed/splits/test.parquet"
BATCH_SIZE = 32

# ðŸ“Œ Cargar el modelo y el tokenizador
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = TFBertForSequenceClassification.from_pretrained(MODEL_PATH)

# ðŸ“Œ Cargar el conjunto de prueba
df = pd.read_parquet(DATA_PATH)
texts, labels = df["text"].tolist(), df["label"].tolist()

# ðŸ“Œ TokenizaciÃ³n de los datos
def tokenize_data(texts, max_length=128):
    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors="tf")

test_tokens = tokenize_data(texts)

# ðŸ“Œ Realizar predicciones
logits = model.predict(test_tokens)[0]
predictions = np.argmax(logits, axis=1)

# ðŸ“Œ Calcular mÃ©tricas
accuracy = accuracy_score(labels, predictions)
report = classification_report(labels, predictions, target_names=["Negativo", "Positivo"])

# ðŸ“Œ Imprimir resultados
print(f"ðŸ“Š PrecisiÃ³n en el conjunto de prueba: {accuracy:.4f}")
print(report)

# ðŸ“Œ Guardar resultado en un archivo
eval_output_path = "src/models/evaluation_results.txt"
with open(eval_output_path, "w") as f:
    f.write(f"Validation Accuracy: {accuracy:.4f}\n")
    f.write(report)

print(f"âœ… Resultados guardados en {eval_output_path}")