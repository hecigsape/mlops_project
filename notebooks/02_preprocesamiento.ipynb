{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24EFuTKQVMIT",
        "outputId": "d6a35253-c272-4edf-d4dc-ffad5750c3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estructura de directorios y archivos creada con √©xito.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Definir la estructura del proyecto\n",
        "directories = [\n",
        "    \"data/raw\",\n",
        "    \"data/processed\",\n",
        "    \"data/external\",\n",
        "    \"data/interim\",\n",
        "\n",
        "]\n",
        "\n",
        "# Crear los directorios\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "print(\"Estructura de directorios y archivos creada con √©xito.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Keif0U9x5nlk",
        "outputId": "47ed231d-8af7-42f1-97b4-7309ea2e4024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando archivo...\n",
            "Descarga completada.\n",
            "Extrayendo archivo...\n",
            "Extracci√≥n completada.\n",
            "Archivo comprimido eliminado.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Definir la URL del archivo y la ruta de destino\n",
        "url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/Software.jsonl.gz\"\n",
        "download_path = \"data/raw/Software.jsonl.gz\"\n",
        "extract_path = \"data/raw/Software.jsonl\"\n",
        "\n",
        "# Crear el directorio si no existe\n",
        "os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
        "\n",
        "# Descargar el archivo\n",
        "print(\"Descargando archivo...\")\n",
        "response = requests.get(url, stream=True)\n",
        "with open(download_path, \"wb\") as file:\n",
        "    shutil.copyfileobj(response.raw, file)\n",
        "print(\"Descarga completada.\")\n",
        "\n",
        "# Extraer el archivo .gz\n",
        "print(\"Extrayendo archivo...\")\n",
        "with gzip.open(download_path, \"rb\") as f_in:\n",
        "    with open(extract_path, \"wb\") as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "print(\"Extracci√≥n completada.\")\n",
        "\n",
        "# Opcional: eliminar el archivo comprimido\n",
        "os.remove(download_path)\n",
        "print(\"Archivo comprimido eliminado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1NREvVu6HIY",
        "outputId": "6487750b-4291-4a2c-dc9a-9217f052662a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vHOggtP8HRV",
        "outputId": "628632f8-eb08-4997-a3a7-ffa7793d5121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m71.7/73.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313502 sha256=d1ec01b93a1f5ea6916c075939ee88426abb92b13cb503fdb32b3534cf49358b\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -P models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6hkSUjI8oPo",
        "outputId": "da13fada-0f27-4459-e4ba-610b23ec6a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-20 00:27:32--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.34.53, 13.226.34.7, 13.226.34.83, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.34.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131266198 (125M) [application/octet-stream]\n",
            "Saving to: ‚Äòmodels/lid.176.bin‚Äô\n",
            "\n",
            "lid.176.bin         100%[===================>] 125.18M   159MB/s    in 0.8s    \n",
            "\n",
            "2025-03-20 00:27:33 (159 MB/s) - ‚Äòmodels/lid.176.bin‚Äô saved [131266198/131266198]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "import fasttext\n",
        "import numpy as np  # Import NumPy\n",
        "file_path = \"data/models/lid.176.bin\"\n",
        "\n",
        "model = fasttext.load_model(file_path)  # Cargar modelo en cada worker\n",
        "\n",
        "def detect_language(text):\n",
        "    if not text:\n",
        "        return \"unknown\"  # Evita errores si `text` es None\n",
        "    label= model.predict([text.replace(\"\\n\", \" \")])\n",
        "    return label[0][0][0].replace(\"__label__\", \"\")\n",
        "\n",
        "# 3Ô∏è‚É£ Crear la UDF en PySpark\n",
        "detect_language_udf = udf(detect_language, StringType())\n",
        "\n",
        "# 4Ô∏è‚É£ Cargar dataset procesado\n",
        "df = spark.read.parquet(\"data/processed/Software_processed.parquet\")\n",
        "\n",
        "# # 5Ô∏è‚É£ Aplicar la detecci√≥n de idioma\n",
        "df = df.withColumn(\"language\", detect_language_udf(col(\"text\")))\n",
        "print(df.columns)  # Verifica si la columna \"language\" fue agregada\n",
        "df.show(20, truncate=True)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tix3rZNW_a1P",
        "outputId": "b885c3b7-077c-4410-e2d5-067e31b02c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asin', 'helpful_vote', 'images', 'parent_asin', 'rating', 'text', 'timestamp', 'title', 'user_id', 'verified_purchase', 'label', 'language']\n",
            "+----------+------------+------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+-----+--------+\n",
            "|      asin|helpful_vote|images|parent_asin|rating|                text|    timestamp|               title|             user_id|verified_purchase|label|language|\n",
            "+----------+------------+------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+-----+--------+\n",
            "|B06XW6RFV2|          38|    []| B06XW6RFV2|   1.0|                  1 |1492261436000|‚ì¢‚ìû ‚ì¢‚ì£‚ì§‚ìü‚ìò‚ìì ‚ìì‚ìû‚ìù'‚ì£ ‚ìñ...|AEBCICFZOHMXJQN5D...|             true|    0|      en|\n",
            "|B019DCHDZK|           0|    []| B019DCHDZK|   1.0| 6300 a month on ...|1617545629074|       too expensive|AFNRECJDZ6HSZ5YJM...|             true|    0|      en|\n",
            "|B007TAX5D8|           2|    []| B007TAX5D8|   2.0| being the free v...|1443469885000|TOO MANY LOCKED L...|AESEQWCUBNZ7TAYQL...|             true|    0|      en|\n",
            "|B0124YIKY2|          11|    []| B0124YIKY2|   1.0| but now tc force...|1459548361000|used to watch Ten...|AGHAXDBCJ7DI7KM3Q...|             true|    0|      en|\n",
            "|B004U7CPWU|           9|    []| B004U7CPWU|   2.0| but on my tablet...|1325541484000|Maybe it's good o...|AE4MCTM2GANQDXSJY...|             true|    0|      en|\n",
            "|B00ESC9J3A|           1|    []| B00ESC9J3A|   2.0| but then they th...|1389761009000|   Okay at first....|AEIQTUZT6LTXEZLY7...|             true|    0|      en|\n",
            "|B078WKYVB9|           0|    []| B078WKYVB9|   1.0| buyer beware ltl...|1598052322457|     BUYER BEWARE!!!|AHVUWJS7UEZ6CJXJY...|             true|    0|      en|\n",
            "|B01M2V5FUT|           1|    []| B01M2V5FUT|   1.0| cant import ofxq...|1482371824000|Bloated, full of ...|AF4YKXA2EVLNQTULW...|             true|    0|      en|\n",
            "|B0055DL1G4|           4|    []| B0055DL1G4|   1.0| cant stand to li...|1334877416000|                 ugh|AHFDW2T4Z3XZHLJB2...|            false|    0|      en|\n",
            "|B004RCUJ9E|           0|    []| B004RCUJ9E|   1.0| checkers which i...|1318832054000|        I don't like|AGNBS7CYJ6DYILPFP...|            false|    0|      en|\n",
            "|B00F2KZVCU|           0|    []| B00F2KZVCU|   1.0|  cool because it is|1427942854000|                cool|AFUED36UNG3PZ3VYK...|             true|    0|      en|\n",
            "|B07YH2WWHP|           0|    []| B07ZP4DMWR|   1.0| deluxe version n...|1594777578716|Rip off at every ...|AETN2AHKGIDVAN6QG...|             true|    0|      en|\n",
            "|B005ZXWMUS|          15|    []| B005ZXWMUS|   1.0| dont know im con...|1594484426665|Is this the one I...|AFTMTJA2GBAIREILF...|            false|    0|      de|\n",
            "|B01MA45UX5|           5|    []| B01MA45UX5|   1.0| every two second...|1502754738098|             Sucksüò§|AGRVF3TZUUKFEYG3H...|             true|    0|      en|\n",
            "|B00BMNM4H6|           3|    []| B00BMNM4H6|   2.0| for about 20 min...|1388341836000|             Fun ...|AECIZBZ7Y3ZX6NZYE...|             true|    0|      en|\n",
            "|B00N28818A|           1|    []| B00N28818A|   1.0| had to install 2...|1500155697514|             Why tho|AF4OJY4VKBGTKKIKE...|             true|    0|      en|\n",
            "|B00GWLHMBQ|           2|    []| B00GWLHMBQ|   1.0| i got this app b...|1403323638000|                  :(|AGFVSDWNUTN2AWYJC...|             true|    0|      en|\n",
            "|B092RSRZN4|          28|    []| B092RSRZN4|   1.0| i opened of the ...|1630456232111|   This game is bad!|AGGY523RINDHSMW22...|             true|    0|      en|\n",
            "|B00CKOYVG8|           0|    []| B00CKOYVG8|   1.0|          il diet it|1661442996516|         GAFIKS SUK!|AFJ5MRKPTSDGGCBVO...|             true|    0|      it|\n",
            "|B00IKZX1ZI|           0|    []| B00IKZX1ZI|   2.0| intended difficu...|1396106563000|        Money Pit!!!|AG55FKDFI7K2K6SW3...|             true|    0|      en|\n",
            "+----------+------------+------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Liberar cach√© de todos los DataFrames\n",
        "spark.catalog.clearCache()\n",
        "import gc\n",
        "\n",
        "# Cerrar sesiones activas\n",
        "for obj in gc.get_objects():\n",
        "    if isinstance(obj, SparkSession):\n",
        "        obj.stop()\n",
        "%reset -f  # Solo en Jupyter Notebook\n",
        "\n",
        "# O en un script de Python:\n",
        "globals().clear()\n",
        "locals().clear()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZN6nuX_95_c",
        "outputId": "bbafac59-b80e-4ec4-ebd4-062fc041898a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Don't know how to reset  #, please run `%reset?` for details\n",
            "Don't know how to reset  solo, please run `%reset?` for details\n",
            "Don't know how to reset  en, please run `%reset?` for details\n",
            "Don't know how to reset  jupyter, please run `%reset?` for details\n",
            "Don't know how to reset  notebook, please run `%reset?` for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf, lower, regexp_replace, count, when\n",
        "from pyspark.sql.window import Window\n",
        "import fasttext\n",
        "from pyspark.sql.types import StringType\n",
        "import os\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "def create_spark_session():\n",
        "    \"\"\"Crea una sesi√≥n de Spark.\"\"\"\n",
        "    return SparkSession.builder.appName(\"PreprocesamientoAmazonReviews\").getOrCreate()\n",
        "\n",
        "def load_data(file_path, spark):\n",
        "    \"\"\"Carga los datos desde Parquet.\"\"\"\n",
        "    print(f\"üì• Cargando datos desde {file_path}...\")\n",
        "    df = spark.read.parquet(file_path)\n",
        "    print(\"‚úÖ Datos cargados correctamente.\")\n",
        "    return df\n",
        "\n",
        "def filter_english_reviews(df):\n",
        "    \"\"\"Filtra solo las rese√±as en ingl√©s si la columna 'language' existe.\"\"\"\n",
        "    if \"language\" in df.columns:\n",
        "        print(\"\\nüóëÔ∏è Eliminando rese√±as en idiomas distintos al ingl√©s...\")\n",
        "        # df = df.filter(col(\"language\") == \"en\")\n",
        "        # df = df.repartition(\"language\").filter(col(\"language\") == \"en\")\n",
        "        # df = df.select(\"language\", \"text\").filter(col(\"language\") == \"en\")\n",
        "        df = df.filter(col(\"language\") == \"en\").select(\"language\", \"label\",\"text\")\n",
        "\n",
        "        print(f\"‚úÖ Total de registros despu√©s del filtro de idioma: {df.count()}\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Advertencia: La columna 'language' no existe en el DataFrame. No se aplica el filtro.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_neutral_reviews(df):\n",
        "    \"\"\"Elimina rese√±as de 3 estrellas para convertirlo en un problema binario.\"\"\"\n",
        "    print(\"\\nüóëÔ∏è Eliminando rese√±as de 3 estrellas...\")\n",
        "    df = df.filter(col(\"rating\") != 3)\n",
        "\n",
        "    # Convertir ratings en clasificaci√≥n binaria (0 = negativo, 1 = positivo)\n",
        "    df = df.withColumn(\"label\", when(col(\"rating\") <= 2, 0).otherwise(1))\n",
        "\n",
        "    print(f\"‚úÖ Total de registros despu√©s de eliminaci√≥n de neutrales: {df.count()}\")\n",
        "    return df\n",
        "\n",
        "def clean_text(df):\n",
        "    \"\"\"Limpia el texto de las rese√±as eliminando caracteres especiales.\"\"\"\n",
        "    print(\"\\nüßπ Limpiando texto...\")\n",
        "    df = df.withColumn(\"text\", lower(col(\"text\")))  # Convertir a min√∫sculas\n",
        "    df = df.withColumn(\"text\", regexp_replace(col(\"text\"), \"[^a-zA-Z0-9\\s]\", \"\"))  # Eliminar caracteres especiales\n",
        "    df = df.withColumn(\"text\", regexp_replace(col(\"text\"), \"\\s+\", \" \"))  # Eliminar espacios extras\n",
        "    print(\"‚úÖ Texto limpiado.\")\n",
        "    return df\n",
        "\n",
        "def remove_duplicates_and_empty(df):\n",
        "    \"\"\"Elimina duplicados y valores nulos.\"\"\"\n",
        "    print(\"\\nüóëÔ∏è Eliminando valores nulos y duplicados...\")\n",
        "    # df = df.filter((col(\"text\").isNotNull()) & (col(\"text\") != \"\"))  # Eliminar rese√±as vac√≠as\n",
        "    # df = df.dropDuplicates([\"text\"])  # Eliminar rese√±as duplicadas\n",
        "    df = df.filter((col(\"text\").isNotNull()) & (col(\"text\") != \"\")).dropDuplicates([\"text\"])\n",
        "\n",
        "    # print(f\"‚úÖ Total de registros despu√©s de limpieza: {df.count()}\")\n",
        "    return df\n",
        "\n",
        "def undersampling(df):\n",
        "    \"\"\"Balancea las clases reduciendo la cantidad de rese√±as positivas (Undersampling).\"\"\"\n",
        "    print(\"\\n‚öñÔ∏è Aplicando Undersampling para balancear clases...\")\n",
        "\n",
        "    # Contar cantidad de positivos y negativos\n",
        "    \"\"\"class_counts = df.groupBy(\"label\").count().collect()\n",
        "    positive_count = next(x[\"count\"] for x in class_counts if x[\"label\"] == 1)\n",
        "    negative_count = next(x[\"count\"] for x in class_counts if x[\"label\"] == 0)\n",
        "    min_class_count = min(positive_count, negative_count)  # Seleccionar la menor cantidad\n",
        "    \"\"\"\n",
        "    # ‚úÖ Contar clases de forma m√°s eficiente sin `collect()`\n",
        "    class_counts = df.groupBy(\"label\").count().toPandas().set_index(\"label\")[\"count\"]\n",
        "    positive_count, negative_count = class_counts.get(1, 0), class_counts.get(0, 0)\n",
        "    min_class_count = min(positive_count, negative_count)\n",
        "\n",
        "    print(f\"üîπ Positivos: {positive_count}, Negativos: {negative_count}\")\n",
        "    print(f\"‚úÖ Reduci√©ndolos a: {min_class_count}\")\n",
        "\n",
        "    \"\"\"# Seleccionar aleatoriamente `min_class_count` rese√±as de cada clase\n",
        "    df_positive = df.filter(col(\"label\") == 1).sample(False, min_class_count / positive_count, seed=42)\n",
        "    df_negative = df.filter(col(\"label\") == 0).sample(False, min_class_count / negative_count, seed=42)\n",
        "\n",
        "    df_balanced = df_positive.union(df_negative)\n",
        "    \"\"\"\n",
        "    # ‚úÖ Filtrar y muestrear en una sola operaci√≥n\n",
        "    df_balanced = (\n",
        "        df.withColumn(\"rand\", F.rand(seed=42))  # Agregar una columna aleatoria para el muestreo\n",
        "        .withColumn(\"rank\", F.row_number().over(Window.partitionBy(\"label\").orderBy(\"rand\")))\n",
        "        .filter(col(\"rank\") <= min_class_count)  # Filtrar para balancear\n",
        "        .drop(\"rand\", \"rank\")  # Limpiar columnas auxiliares\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Total de registros despu√©s del balanceo: {df_balanced.count()}\")\n",
        "    return df_balanced\n",
        "\n",
        "def save_cleaned_data(df, output_path):\n",
        "    \"\"\"Guarda los datos procesados en Parquet.\"\"\"\n",
        "    print(f\"\\nüíæ Guardando datos procesados en {output_path}...\")\n",
        "    df.write.mode(\"overwrite\").parquet(output_path)\n",
        "    print(\"‚úÖ Datos guardados correctamente.\")\n",
        "\n",
        "# Funci√≥n para cargar el modelo FastText en cada worker de Spark\n",
        "def get_fasttext_model():\n",
        "    \"\"\"Carga el modelo FastText en cada worker solo una vez.\"\"\"\n",
        "    return fasttext.load_model(\"models/lid.176.bin\")\n",
        "\n",
        "def detect_language(text):\n",
        "    \"\"\"Detecta el idioma usando FastText.\"\"\"\n",
        "    try:\n",
        "        if not text:\n",
        "            return \"unknown\"\n",
        "\n",
        "        # Cargar modelo FastText en cada worker\n",
        "        model = get_fasttext_model()\n",
        "\n",
        "        label = model.predict([text.replace(\"\\n\", \" \")])\n",
        "        return label[0][0][0].replace(\"__label__\", \"\")\n",
        "    except Exception:\n",
        "        return \"unknown\"\n",
        "\n",
        "def check_and_download_file(file_path, url):\n",
        "    \"\"\"\n",
        "    Verifica si el archivo existe en la ruta especificada.\n",
        "    Si no existe, lo descarga usando wget.\n",
        "\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"‚úÖ El archivo ya existe: {file_path}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è El archivo no existe. Descargando desde: {url}\")\n",
        "        os.system(f\"wget {url} -P {os.path.dirname(file_path)}\")\n",
        "        print(\"‚úÖ Descarga completada.\")\n",
        "\n",
        "detect_language_udf = udf(detect_language, StringType())\n",
        "\n",
        "def add_language_column(df):\n",
        "    # Convertir la funci√≥n en UDF para PySpark\n",
        "\n",
        "    \"\"\"A√±ade la columna 'language' con la detecci√≥n de idioma.\"\"\"\n",
        "    print(\"\\nüåç Detectando idioma de las rese√±as...\")\n",
        "    df = df.withColumn(\"language\", detect_language_udf(col(\"text\")))\n",
        "    print(\"‚úÖ Detecci√≥n de idioma completada.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XXr4JcIlIoMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # üìå Definir rutas\n",
        "  interim_data_path = \"data/interim/Software_interim.parquet\"\n",
        "  processed_data_path = \"data/processed/Software_processed.parquet\"\n",
        "  from pyspark import SparkContext\n",
        "\n",
        "  # Crear sesi√≥n de Spark\n",
        "  spark = create_spark_session()\n",
        "\n",
        "  # Cargar datos\n",
        "  df = load_data(interim_data_path, spark)\n",
        "  df.printSchema()\n",
        "  df = df.select(col(\"text\"), col(\"rating\"))\n",
        "  df = remove_neutral_reviews(df)\n",
        "  # # Aplicar detecci√≥n de idioma\n",
        "  df.show(5, truncate=True)\n",
        "\n",
        "\n",
        "  file_path = \"data/models/lid.176.bin\"\n",
        "  url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\"\n",
        "  check_and_download_file(file_path, url)\n",
        "  # df = spark.read.parquet(\"data/processed/Software_processed.parquet\")\n",
        "  res=detect_language(\"hola como estas soy de colomb\")\n",
        "  # Definir la funci√≥n con carga de modelo en cada worker\n",
        "  def detect_language_udf():\n",
        "      model = None  # Variable para almacenar el modelo en cach√©\n",
        "\n",
        "      def detect_language(text):\n",
        "          nonlocal model\n",
        "          if model is None:\n",
        "              model = fasttext.load_model(file_path)  # ‚úÖ Carga del modelo en cada worker\n",
        "          try:\n",
        "              if not text:\n",
        "                  return \"unknown\"\n",
        "              label = model.predict([text.replace(\"\\n\", \" \")])\n",
        "              return label[0][0][0].replace(\"__label__\", \"\")\n",
        "          except Exception:\n",
        "              return \"unknown\"\n",
        "\n",
        "      return detect_language\n",
        "\n",
        "  # Convertir la funci√≥n en una UDF\n",
        "  detect_language = udf(detect_language_udf(), StringType())\n",
        "  # Aplicar la UDF al DataFrame de Spark\n",
        "  df = df.withColumn(\"language\", detect_language(col(\"text\")))\n",
        "  df.show(5, truncate=True)\n",
        "\n",
        "\n",
        "  # # üìå Verificar los datos antes de seguir\n",
        "  # df.select(\"text\", \"language\").show(5, truncate=True)\n",
        "\n",
        "  # # Eliminar rese√±as neutrales y convertir a clasificaci√≥n binaria\n",
        "  df = filter_english_reviews(df)\n",
        "  # df = remove_neutral_reviews(df)\n",
        "  df.show(5, truncate=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNL4vADkTuYi",
        "outputId": "fa11b38d-84a0-4605-f3ca-c109e87cc81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Cargando datos desde data/interim/Software_interim.parquet...\n",
            "‚úÖ Datos cargados correctamente.\n",
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful_vote: long (nullable = true)\n",
            " |-- images: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- attachment_type: string (nullable = true)\n",
            " |    |    |-- large_image_url: string (nullable = true)\n",
            " |    |    |-- medium_image_url: string (nullable = true)\n",
            " |    |    |-- small_image_url: string (nullable = true)\n",
            " |-- parent_asin: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- verified_purchase: boolean (nullable = true)\n",
            "\n",
            "\n",
            "üóëÔ∏è Eliminando rese√±as de 3 estrellas...\n",
            "‚úÖ Total de registros despu√©s de eliminaci√≥n de neutrales: 4460825\n",
            "+--------------------+------+-----+\n",
            "|                text|rating|label|\n",
            "+--------------------+------+-----+\n",
            "|Great product for...|   5.0|    1|\n",
            "|My 6 year old and...|   5.0|    1|\n",
            "|Loving ABC Mouse....|   5.0|    1|\n",
            "|I love this game,...|   5.0|    1|\n",
            "|Only on level 10 ...|   5.0|    1|\n",
            "+--------------------+------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "‚ö†Ô∏è El archivo no existe. Descargando desde: https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "‚úÖ Descarga completada.\n",
            "+--------------------+------+-----+--------+\n",
            "|                text|rating|label|language|\n",
            "+--------------------+------+-----+--------+\n",
            "|Great product for...|   5.0|    1|      en|\n",
            "|My 6 year old and...|   5.0|    1|      en|\n",
            "|Loving ABC Mouse....|   5.0|    1|      en|\n",
            "|I love this game,...|   5.0|    1|      en|\n",
            "|Only on level 10 ...|   5.0|    1|      en|\n",
            "+--------------------+------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "üóëÔ∏è Eliminando rese√±as en idiomas distintos al ingl√©s...\n",
            "‚úÖ Total de registros despu√©s del filtro de idioma: 4345746\n",
            "+--------+-----+--------------------+\n",
            "|language|label|                text|\n",
            "+--------+-----+--------------------+\n",
            "|      en|    1|Great product for...|\n",
            "|      en|    1|My 6 year old and...|\n",
            "|      en|    1|Loving ABC Mouse....|\n",
            "|      en|    1|I love this game,...|\n",
            "|      en|    1|Only on level 10 ...|\n",
            "+--------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # # # Preprocesar datos\n",
        "  df = clean_text(df)\n",
        "  df = remove_duplicates_and_empty(df)\n",
        "\n",
        "  # # Guardar datos procesados\n",
        "  save_cleaned_data(df, processed_data_path)\n",
        "\n",
        "  print(\"\\nüéØ Proceso de preprocesamiento completado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pWKKJU3LiYF",
        "outputId": "b8a1c0d6-d1d3-42dc-8b41-c16c6f804e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßπ Limpiando texto...\n",
            "‚úÖ Texto limpiado.\n",
            "\n",
            "üóëÔ∏è Eliminando valores nulos y duplicados...\n",
            "\n",
            "üíæ Guardando datos procesados en data/processed/Software_processed.parquet...\n",
            "‚úÖ Datos guardados correctamente.\n",
            "\n",
            "üéØ Proceso de preprocesamiento completado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # # Aplicar Undersampling\n",
        "  df = undersampling(df)\n",
        "\n",
        "  # # Guardar datos procesados\n",
        "  save_cleaned_data(df, processed_data_path)\n",
        "\n",
        "  print(\"\\nüéØ Proceso de preprocesamiento completado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilzZXcX8U0_F",
        "outputId": "0d946af0-11ed-4aac-fa4d-6c4f9b35c93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öñÔ∏è Aplicando Undersampling para balancear clases...\n",
            "üîπ Positivos: 2748554, Negativos: 803325\n",
            "‚úÖ Reduci√©ndolos a: 803325\n",
            "‚úÖ Total de registros despu√©s del balanceo: 1606650\n",
            "\n",
            "üíæ Guardando datos procesados en data/processed/Software_processed.parquet...\n",
            "‚úÖ Datos guardados correctamente.\n",
            "\n",
            "üéØ Proceso de preprocesamiento completado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data.zip\n",
        "!zip -r data.zip data\n",
        "from google.colab import files\n",
        "files.download(\"data.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "DMazN3RMbHgx",
        "outputId": "8ee6790d-4f15-4b9e-ee4d-9549b82f288d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data/ (stored 0%)\n",
            "  adding: data/processed/ (stored 0%)\n",
            "  adding: data/processed/Software_processed.parquet/ (stored 0%)\n",
            "  adding: data/processed/Software_processed.parquet/.part-00000-fdac93fb-e293-483d-b1b8-f10dfcd7cd52-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/processed/Software_processed.parquet/._SUCCESS.crc (stored 0%)\n",
            "  adding: data/processed/Software_processed.parquet/.part-00001-fdac93fb-e293-483d-b1b8-f10dfcd7cd52-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/processed/Software_processed.parquet/_SUCCESS (stored 0%)\n",
            "  adding: data/processed/Software_processed.parquet/part-00001-fdac93fb-e293-483d-b1b8-f10dfcd7cd52-c000.snappy.parquet (deflated 12%)\n",
            "  adding: data/processed/Software_processed.parquet/part-00000-fdac93fb-e293-483d-b1b8-f10dfcd7cd52-c000.snappy.parquet (deflated 12%)\n",
            "  adding: data/interim/ (stored 0%)\n",
            "  adding: data/interim/Software_interim.parquet/ (stored 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00006-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00012-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00004-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00012-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00013-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00005-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00007-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00003-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00010-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00005-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00010-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/._SUCCESS.crc (stored 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00008-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00009-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00008-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00009-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00000-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00011-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00004-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00000-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00007-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00002-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00002-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00001-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 14%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00013-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/interim/Software_interim.parquet/_SUCCESS (stored 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00006-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00001-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/.part-00003-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet.crc (deflated 0%)\n",
            "  adding: data/interim/Software_interim.parquet/part-00011-875cac4e-3bad-4099-bd94-9b22a9e6e345-c000.snappy.parquet (deflated 15%)\n",
            "  adding: data/models/ (stored 0%)\n",
            "  adding: data/models/lid.176.bin (deflated 6%)\n",
            "  adding: data/raw/ (stored 0%)\n",
            "  adding: data/raw/Software.jsonl (deflated 73%)\n",
            "  adding: data/external/ (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fc973175-4d7e-40c2-8d5a-1b8395c7fa52\", \"data.zip\", 1324838798)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}