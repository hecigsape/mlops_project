

# ğŸš€ Proyecto MLOps - Machine Learning Engineer 

Este repositorio contiene la soluciÃ³n para la prueba tÃ©cnica de **Machine Learning Engineer - GenAI**, diseÃ±ada para demostrar habilidades en **procesamiento de datos, modelado, despliegue y MLOps**.  

## ğŸ“‚ Estructura de Directorios

Para garantizar una soluciÃ³n escalable y mantenible, se ha diseÃ±ado la siguiente estructura de directorios:

```plaintext
mlops_project/
â”‚â”€â”€ data/                     # Almacenamiento de datos
â”‚   â”œâ”€â”€ raw/                  # Datos sin procesar
â”‚   â”œâ”€â”€ processed/            # Datos listos para entrenamiento
â”‚   â”œâ”€â”€ external/             # Datos de terceros
â”‚   â””â”€â”€ interim/              # Datos en transformaciÃ³n
â”‚
â”‚â”€â”€ notebooks/                # Jupyter Notebooks para EDA y experimentaciÃ³n
â”‚   â”œâ”€â”€ 01_exploracion.ipynb  
â”‚   â”œâ”€â”€ 02_preprocesamiento.ipynb  
â”‚   â””â”€â”€ 03_entrenamiento.ipynb  
â”‚
â”‚â”€â”€ src/                      # CÃ³digo fuente
â”‚   â”œâ”€â”€ data/                 # Ingesta y preprocesamiento de datos
â”‚   â”‚   â”œâ”€â”€ ingestion.py       
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   
â”‚   â”‚   â”œâ”€â”€ etl_pipeline.py   
â”‚   â”‚   â””â”€â”€ data_loader.py    
â”‚   â”‚
â”‚   â”œâ”€â”€ models/               # Modelos entrenados y scripts
â”‚   â”‚   â”œâ”€â”€ train.py          # Entrenamiento de modelos
â”‚   â”‚   â”œâ”€â”€ evaluate.py       # EvaluaciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ predict.py        # PredicciÃ³n en batch
â”‚   â”‚   â”œâ”€â”€ model_v1.pkl      # Modelo serializado versiÃ³n 1
â”‚   â”‚   â”œâ”€â”€ model_v2.pkl      # Modelo serializado versiÃ³n 2
â”‚   â”‚   â””â”€â”€ tokenizer.pkl     # Tokenizador serializado
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/           # Scripts para despliegue en AWS
â”‚   â”‚   â”œâ”€â”€ serve_model.py    
â”‚   â”‚   â”œâ”€â”€ aws_lambda.py    
â”‚   â”‚   â”œâ”€â”€ sagemaker_deploy.py  
â”‚   â”‚   â””â”€â”€ requirements.txt  
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/           # Scripts para monitoreo y alertas
â”‚   â”‚   â”œâ”€â”€ model_monitor.py  
â”‚   â”‚   â”œâ”€â”€ drift_detection.py  
â”‚   â”‚   â””â”€â”€ alert_system.py  
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                # Funciones auxiliares
â”‚   â”‚   â”œâ”€â”€ helpers.py        
â”‚   â”‚   â”œâ”€â”€ logger.py         
â”‚   â”‚   â””â”€â”€ config.py         
â”‚
â”‚â”€â”€ tests/                    # Pruebas unitarias y de integraciÃ³n
â”‚   â”œâ”€â”€ test_preprocessing.py #ruebas para preprocesamiento
â”‚   â”œâ”€â”€ test_training.py      #ruebas para entrenamiento del modelo
â”‚   â””â”€â”€ test_evaluation.py    #ruebas para evaluaciÃ³n del modelo
â”‚   â””â”€â”€ test_deployment.py    #ruebas para despliegue en SageMaker
â”‚
â”‚â”€â”€ configs/                  # Configuraciones del proyecto
â”‚   â”œâ”€â”€ config.yaml           
â”‚   â”œâ”€â”€ logging.yaml          
â”‚   â”œâ”€â”€ model_params.yaml     
â”‚   â””â”€â”€ aws_config.json       
â”‚
â”‚â”€â”€ .github/                  # ConfiguraciÃ³n de CI/CD con GitHub Actions
â”‚   â”œâ”€â”€ workflows/            
â”‚   â”‚   â”œâ”€â”€ ci.yml            
â”‚   â”‚   â”œâ”€â”€ cd.yml            
â”‚   â”‚   â””â”€â”€ monitoring.yml    
â”‚
â”‚â”€â”€ README.md                 # DocumentaciÃ³n del proyecto
â”‚â”€â”€ requirements.txt           # Dependencias del proyecto
â”‚â”€â”€ setup.py                   # InstalaciÃ³n del paquete
â”‚â”€â”€ Dockerfile                 # Contenedor para despliegue
â”‚â”€â”€ Makefile                   # Comandos automatizados
```

---

## ğŸ“Œ **ExplicaciÃ³n de la Estructura**
| **Directorio**  | **DescripciÃ³n**  |
|----------------|---------------|
| `data/` | Contiene los datos en diferentes etapas del pipeline. |
| `notebooks/` | Jupyter notebooks para anÃ¡lisis exploratorio y experimentaciÃ³n. |
| `src/data/` | CÃ³digo para ingesta y preprocesamiento de datos. |
| `src/models/` | Scripts de entrenamiento y evaluaciÃ³n, junto con modelos serializados. |
| `src/deployment/` | Scripts para desplegar en AWS (SageMaker, Lambda). |
| `src/monitoring/` | Scripts para monitoreo del modelo en producciÃ³n. |
| `src/utils/` | Funciones auxiliares como logging y configuraciÃ³n. |
| `tests/` | Pruebas unitarias e integraciÃ³n. |
| `configs/` | Archivos de configuraciÃ³n YAML/JSON. |
| `.github/workflows/` | Pipelines de CI/CD en GitHub Actions. |
| `Dockerfile` | ConfiguraciÃ³n para despliegue en contenedores. |
| `Makefile` | AutomatizaciÃ³n de comandos. |

---

## ğŸ”„ **Manejo de Versionado del Pipeline y Modelos**
Para garantizar la **reproducibilidad y trazabilidad**, seguimos estas estrategias:

### **1ï¸âƒ£ Versionado del Pipeline de Preprocesamiento**
- Cada modificaciÃ³n en el pipeline de datos (`src/data/etl_pipeline.py`) se documenta con:
  - **Control de versiones en Git** (`etl_pipeline_v1.py`, `etl_pipeline_v2.py`, etc.).
  - **Etiquetas en Git** (`v1.0.0`, `v1.1.0`, etc.).
  - **Registro en MLflow** para seguimiento de cambios en preprocesamiento.

### **2ï¸âƒ£ Versionado de Modelos Entrenados**
- Cada modelo serializado (`.pkl`) se almacena con su versiÃ³n en `src/models/`:
  - `model_v1.pkl`, `model_v2.pkl`, etc.
- Se utiliza **MLflow y DVC (Data Version Control)** para:
  - Registrar mÃ©tricas de cada versiÃ³n.
  - Mantener historial de entrenamientos y mejoras.

### **3ï¸âƒ£ Versionado de Configuraciones**
- Los hiperparÃ¡metros y configuraciÃ³n del modelo se almacenan en `configs/model_params.yaml`.
- Se mantiene control de cambios con Git y se etiquetan las versiones.

---

## ğŸš€ **CÃ³mo Ejecutar el Proyecto**
### **1ï¸âƒ£ Clonar el Repositorio**
```bash
git clone https://github.com/hecigsape/mlops_project
cd mlops_project
```

### **2ï¸âƒ£ Instalar Dependencias**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Ejecutar el Pipeline**
```bash
python src/data/etl_pipeline.py
python src/models/train.py
python src/models/evaluate.py
```

### **4ï¸âƒ£ Desplegar en AWS SageMaker**
```bash
python src/deployment/sagemaker_deploy.py
```

---

## ğŸ“Š **Monitoreo del Modelo**
- Se ejecuta con:
```bash
python src/monitoring/model_monitor.py
```
- Detecta **drift en los datos** y envÃ­a **alertas automÃ¡ticas**.

---

## ğŸ” **Seguridad Implementada**
- **Cifrado de datos** en AWS S3 (AES-256).
- **Roles IAM** con privilegios mÃ­nimos.
- **AuditorÃ­a y logs** en AWS CloudTrail.
- **Monitoreo de accesos** a la API del modelo.


---

## **ğŸ“‚ Diccionario de Datos** ğŸ“‘  
ğŸ“Œ **DescripciÃ³n de las columnas del dataset despuÃ©s del preprocesamiento.**  

| **Columna**          | **DescripciÃ³n** |
|----------------------|----------------|
| `asin`              | Identificador Ãºnico del producto en Amazon. |
| `helpful_vote`      | NÃºmero de votos indicando si la reseÃ±a fue Ãºtil. |
| `images`            | URLs de imÃ¡genes asociadas al producto. |
| `parent_asin`       | Identificador del producto principal (si pertenece a una familia de productos). |
| `rating`            | CalificaciÃ³n del usuario (1-5 estrellas). |
| `text`              | Texto completo de la reseÃ±a despuÃ©s de limpieza. |
| `timestamp`         | Fecha de la reseÃ±a en formato UNIX. |
| `title`             | TÃ­tulo de la reseÃ±a. |
| `user_id`           | ID del usuario que dejÃ³ la reseÃ±a. |
| `verified_purchase` | `True` si la compra fue verificada, `False` en caso contrario. |
| `language`          | Idioma detectado en la reseÃ±a (aÃ±adido durante el preprocesamiento). |

---

## **ğŸ“Œ Modelo de Datos Conceptual** ğŸ¯  
ğŸ“Œ **CÃ³mo se estructuran los datos despuÃ©s del preprocesamiento:**  
- **Entrada del modelo:** `text` (reseÃ±a), `title` (tÃ­tulo), `verified_purchase`.  
- **Etiqueta (`y`) del modelo:** `rating` (1-5 estrellas).  
- **Campos eliminados:** `asin`, `images`, `parent_asin`, `timestamp`, `user_id`.  
- **Campos generados:** `language` (para filtrar datos por idioma).  

---

## **ğŸ“Œ Requerimientos de Hardware** ğŸ’»  
ğŸ“Œ **Para entrenar el modelo:**  
- **MÃ­nimo:** 8GB RAM, 4 CPU.  
- **Recomendado:** 16GB RAM, GPU NVIDIA (para modelos mÃ¡s complejos como Transformers).  
- **Opcional:** TPU en Google Colab para acelerar entrenamiento.  

---

## **ğŸ“Œ Manejo del Desbalance de Clases** âš–  
ğŸ“Œ **Estrategia aplicada para evitar sesgos en el modelo:**  
- **(Undersampling):** Se redujo la cantidad de reseÃ±as con 5 estrellas para igualar las otras clases.  
  

---

## **ğŸ“Œ EvaluaciÃ³n del Modelo** ğŸ“Š  
ğŸ“Œ **MÃ©tricas de evaluaciÃ³n:**  
- **Accuracy:** Para medir el desempeÃ±o general.  
- **F1-score:** Para evaluar rendimiento en clases desbalanceadas.  
- **Matriz de ConfusiÃ³n:** Para identificar errores comunes.  

ğŸ“Œ **ValidaciÃ³n aplicada:**  
- **Hold-out (80%-20%)** para dividir entrenamiento y prueba.  
- **Cross-validation (k-fold)** para estabilidad del modelo.  


---
## ğŸ”¥ Arquitectura del Proyecto

Este repositorio implementa una arquitectura basada en **MLOps** utilizando AWS, GitHub Actions y SageMaker. A continuaciÃ³n, se muestra un diagrama del flujo completo.

**DescripciÃ³n del Diagrama de Arquitectura MLOps:**

- ğŸ”„ **Control de Versiones:** IntegraciÃ³n con GitHub y pipelines de CI/CD automatizados
- ğŸ“Š **Procesamiento:** Datos almacenados en S3 y procesados con AWS Lambda
- ğŸ¯ **Entrenamiento:** SageMaker gestiona el entrenamiento con seguimiento en MLflow
- ğŸŒ **Despliegue:** Endpoints de SageMaker expuestos vÃ­a API Gateway
- ğŸ“¡ **Monitoreo:** SupervisiÃ³n continua con CloudWatch y alertas SNS

![alt text](image-1.png)

![alt text](image-2.png)

![alt text](image-3.png)

![alt text](image-4.png)